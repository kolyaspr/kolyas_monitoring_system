"""
Streamlit Ğ¿Ñ€Ğ¸Ğ»Ğ¾Ğ¶ĞµĞ½Ğ¸Ğµ Ğ´Ğ»Ñ Ğ¼Ğ¾Ğ½Ğ¸Ñ‚Ğ¾Ñ€Ğ¸Ğ½Ğ³Ğ° Ğ´Ğ¸ÑÑ†Ğ¸Ğ¿Ğ»Ğ¸Ğ½Ñ‹ Ğ½Ğ° Ğ·Ğ°Ğ½ÑÑ‚Ğ¸ÑÑ…
Ğ”ĞµÑ‚ĞµĞºÑ‚Ğ¸Ñ€ÑƒĞµÑ‚ Ğ½Ğ°Ñ€ÑƒÑˆĞµĞ½Ğ¸Ñ: ÑĞ¾Ğ½, Ñ‚ĞµĞ»ĞµÑ„Ğ¾Ğ½, ĞµĞ´Ğ°/Ğ½Ğ°Ğ¿Ğ¸Ñ‚ĞºĞ¸
"""
import os
import cv2
import time
import pickle
import tempfile
import numpy as np
import streamlit as st
from datetime import datetime
from pathlib import Path

# Ğ˜Ğ¼Ğ¿Ğ¾Ñ€Ñ‚ Ğ¼Ğ¾Ğ´ÑƒĞ»ĞµĞ¹
from modules.detection import ViolationDetector
from modules.face_recognition import FaceRecognizer
from modules.video_processor import VideoProcessor
from modules.detection_logic import (
    process_frame_for_detection_correct,
    draw_detections_with_boxes,
    draw_sleep_indicator,
    load_face_resources,
    analyze_video_segment
)

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ĞšĞĞĞ¤Ğ˜Ğ“Ğ£Ğ ĞĞ¦Ğ˜Ğ¯ STREAMLIT
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

st.set_page_config(
    page_title="ĞœĞ¾Ğ½Ğ¸Ñ‚Ğ¾Ñ€ Ğ”Ğ¸ÑÑ†Ğ¸Ğ¿Ğ»Ğ¸Ğ½Ñ‹",
    page_icon="ğŸ“¹",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ĞšĞ°ÑÑ‚Ğ¾Ğ¼Ğ½Ñ‹Ğ¹ ÑÑ‚Ğ¸Ğ»ÑŒ
st.markdown("""
<style>
    .main-title {
        color: #2c3e50;
        text-align: center;
        font-size: 2.5em;
        font-weight: bold;
        margin-bottom: 20px;
    }
    .metric-container {
        background-color: #ecf0f1;
        padding: 20px;
        border-radius: 10px;
        margin: 10px 0;
    }
    .violation-badge {
        display: inline-block;
        padding: 8px 12px;
        border-radius: 20px;
        color: white;
        font-weight: bold;
        margin: 5px;
    }
    .sleeping { background-color: #e74c3c; }
    .phone { background-color: #e67e22; }
    .food { background-color: #3498db; }
    .bottle { background-color: #9b59b6; }
</style>
""", unsafe_allow_html=True)

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Ğ˜ĞĞ˜Ğ¦Ğ˜ĞĞ›Ğ˜Ğ—ĞĞ¦Ğ˜Ğ¯ SESSION STATE
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

if 'detector' not in st.session_state:
    st.session_state.detector = None

if 'face_recognizer' not in st.session_state:
    st.session_state.face_recognizer = None

if 'video_processor' not in st.session_state:
    st.session_state.video_processor = VideoProcessor()

if 'violations_log' not in st.session_state:
    st.session_state.violations_log = []

if 'processing' not in st.session_state:
    st.session_state.processing = False

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Ğ¤Ğ£ĞĞšĞ¦Ğ˜Ğ˜ ĞšĞ­Ğ¨Ğ˜Ğ ĞĞ’ĞĞĞ˜Ğ¯
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

@st.cache_resource
def load_detector(model_path):
    """ĞšÑÑˆĞ¸Ñ€ÑƒĞµÑ‚ Ğ´ĞµÑ‚ĞµĞºÑ‚Ğ¾Ñ€ Ğ½Ğ°Ñ€ÑƒÑˆĞµĞ½Ğ¸Ğ¹"""
    return ViolationDetector(model_path)

@st.cache_resource
def load_face_recognizer(db_path):
    """ĞšÑÑˆĞ¸Ñ€ÑƒĞµÑ‚ Ñ€Ğ°ÑĞ¿Ğ¾Ğ·Ğ½Ğ°Ğ²Ğ°Ñ‚ĞµĞ»ÑŒ Ğ»Ğ¸Ñ†"""
    return FaceRecognizer(db_path if os.path.exists(db_path) else None)

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Ğ’Ğ¡ĞŸĞĞœĞĞ“ĞĞ¢Ğ•Ğ›Ğ¬ĞĞ«Ğ• Ğ¤Ğ£ĞĞšĞ¦Ğ˜Ğ˜ ĞĞ‘Ğ ĞĞ‘ĞĞ¢ĞšĞ˜
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def process_frame_for_detection(current_time, detections_in_frame, sleep_start_time, sleep_buffer):
    """
    ĞŸĞ ĞĞ’Ğ˜Ğ›Ğ¬ĞĞĞ¯ Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ° ĞºĞ°Ğ´Ñ€Ğ° Ğ´Ğ»Ñ Ğ¿Ğ¾Ğ»ÑƒÑ‡ĞµĞ½Ğ¸Ñ confirmed_violations.
    Ğ˜ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµÑ‚ Ğ»Ğ¾Ğ³Ğ¸ĞºÑƒ Ğ¸Ğ· standalone ÑĞºÑ€Ğ¸Ğ¿Ñ‚Ğ°.
    
    Args:
        current_time: Ñ‚ĞµĞºÑƒÑ‰ĞµĞµ Ğ²Ñ€ĞµĞ¼Ñ
        detections_in_frame: set Ğ½Ğ°Ğ·Ğ²Ğ°Ğ½Ğ¸Ğ¹ Ğ¾Ğ±Ğ½Ğ°Ñ€ÑƒĞ¶ĞµĞ½Ğ½Ñ‹Ñ… ĞºĞ»Ğ°ÑÑĞ¾Ğ² {'sleeping', 'phone', ...}
        sleep_start_time: Ğ²Ñ€ĞµĞ¼Ñ Ğ½Ğ°Ñ‡Ğ°Ğ»Ğ° Ğ¾Ğ±Ğ½Ğ°Ñ€ÑƒĞ¶ĞµĞ½Ğ¸Ñ ÑĞ½Ğ°
        sleep_buffer: Ğ±ÑƒÑ„ĞµÑ€ Ğ¿Ğ¾Ğ´Ñ‚Ğ²ĞµÑ€Ğ¶Ğ´ĞµĞ½Ğ¸Ñ ÑĞ½Ğ° Ğ² ÑĞµĞºÑƒĞ½Ğ´Ğ°Ñ…
    
    Returns:
        (confirmed_violations, new_sleep_start_time, new_last_detection_time)
    """
    return process_frame_for_detection_correct(current_time, detections_in_frame, sleep_start_time, sleep_buffer)


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Ğ¤Ğ£ĞĞšĞ¦Ğ˜Ğ˜ ĞĞ‘Ğ ĞĞ‘ĞĞ¢ĞšĞ˜ Ğ’Ğ˜Ğ”Ğ•Ğ (Ğ¾Ğ¿Ñ€ĞµĞ´ĞµĞ»ĞµĞ½Ñ‹ Ğ¿ĞµÑ€ĞµĞ´ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸ĞµĞ¼)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def process_webcam(video_container, metrics_container, frame_skip=2, buffer_seconds=10, sleep_buffer=10, face_db_path="students.pkl", face_similarity=0.5):
    """ĞĞ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ° Ğ¿Ğ¾Ñ‚Ğ¾ĞºĞ° Ğ²ĞµĞ±-ĞºĞ°Ğ¼ĞµÑ€Ñ‹"""
    try:
        st.info("Ğ˜Ğ½Ğ¸Ñ†Ğ¸Ğ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ Ğ²ĞµĞ±-ĞºĞ°Ğ¼ĞµÑ€Ñ‹... (Ğ¼Ğ¾Ğ¶ĞµÑ‚ Ğ·Ğ°Ğ½ÑÑ‚ÑŒ 3-5 ÑĞµĞºÑƒĞ½Ğ´)")
        
        cap = cv2.VideoCapture(0)  # 0 - Ğ¿Ğ¾ ÑƒĞ¼Ğ¾Ğ»Ñ‡Ğ°Ğ½Ğ¸Ñ Ğ²ĞµĞ±-ĞºĞ°Ğ¼ĞµÑ€Ğ°
        
        # ĞŸĞ¾Ğ¿Ñ‹Ñ‚ĞºĞ° Ğ¸ÑĞ¿Ñ€Ğ°Ğ²Ğ¸Ñ‚ÑŒ Ğ²Ñ€ĞµĞ¼Ñ Ğ¸Ğ½Ğ¸Ñ†Ğ¸Ğ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¸
        cap.set(cv2.CAP_PROP_BUFFERSIZE, 1)  # ĞœĞ¸Ğ½Ğ¸Ğ¼Ğ°Ğ»ÑŒĞ½Ñ‹Ğ¹ Ğ±ÑƒÑ„ĞµÑ€
        
        # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ĞºĞ° Ñ‡Ñ‚Ğ¾ ĞºĞ°Ğ¼ĞµÑ€Ğ° Ğ¾Ñ‚ĞºÑ€Ñ‹Ñ‚Ğ°
        if not cap.isOpened():
            st.error("ĞĞµ ÑƒĞ´Ğ°Ğ»Ğ¾ÑÑŒ Ğ¿Ğ¾Ğ´ĞºĞ»ÑÑ‡Ğ¸Ñ‚ÑŒÑÑ Ğº Ğ²ĞµĞ±-ĞºĞ°Ğ¼ĞµÑ€Ğµ. ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑŒÑ‚Ğµ ĞµÑ‘ Ğ¿Ğ¾Ğ´ĞºĞ»ÑÑ‡ĞµĞ½Ğ¸Ğµ.")
            st.session_state.processing = False
            return
        
        # ĞŸĞ¾Ğ¿Ñ€Ğ¾Ğ±ÑƒĞµĞ¼ ÑƒÑÑ‚Ğ°Ğ½Ğ¾Ğ²Ğ¸Ñ‚ÑŒ Ğ¿Ğ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ñ‹ ĞºĞ°Ğ¼ĞµÑ€Ñ‹ Ğ´Ğ»Ñ ÑƒĞ»ÑƒÑ‡ÑˆĞµĞ½Ğ¸Ñ ĞºĞ°Ñ‡ĞµÑÑ‚Ğ²Ğ°
        cap.set(cv2.CAP_PROP_FRAME_WIDTH, 1280)
        cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 720)
        cap.set(cv2.CAP_PROP_FPS, 30)
        
        fps = cap.get(cv2.CAP_PROP_FPS)
        if fps == 0:
            fps = 30
        
        width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
        height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
        
        # Ğ¡Ğ¾Ğ·Ğ´Ğ°Ğ½Ğ¸Ğµ Ğ²Ğ¸Ğ´ĞµĞ¾Ğ·Ğ°Ğ¿Ğ¸ÑĞµĞ¹
        st.session_state.video_processor.setup_output_dirs()
        
        # ĞœĞµÑ‚Ñ€Ğ¸ĞºĞ¸
        metrics = {
            'total_frames': 0,
            'violations': {},
            'recording': False,
            'frames_processed': 0
        }
        
        frame_count = 0
        sleep_start_time = None
        last_detection_time = None
        last_recording_end_time = None
        recording = False
        rec_violations = set()
        current_segment_path = None
        last_detections = {}
        last_confirmed_violations = set()
        
        progress_bar = st.progress(0)
        status_text = st.empty()
        frame_placeholder = st.empty()
        metrics_placeholder = st.empty()
        
        st.success("Ğ’ĞµĞ±-ĞºĞ°Ğ¼ĞµÑ€Ğ° Ğ³Ğ¾Ñ‚Ğ¾Ğ²Ğ°!")
        st.info("Ğ¢Ñ€Ğ°Ğ½ÑĞ»ÑÑ†Ğ¸Ñ Ñ Ğ²ĞµĞ±-ĞºĞ°Ğ¼ĞµÑ€Ñ‹ (Ğ¾Ğ±Ğ½Ğ¾Ğ²Ğ»ÑĞµÑ‚ÑÑ Ğ² Ñ€ĞµĞ°Ğ»ÑŒĞ½Ğ¾Ğ¼ Ğ²Ñ€ĞµĞ¼ĞµĞ½Ğ¸)...")
        stop_button = st.button("ĞÑÑ‚Ğ°Ğ½Ğ¾Ğ²Ğ¸Ñ‚ÑŒ Ñ‚Ñ€Ğ°Ğ½ÑĞ»ÑÑ†Ğ¸Ñ", key="webcam_stop")
        
        # ĞĞ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ° Ğ´Ğ¾ Ğ½Ğ°Ğ¶Ğ°Ñ‚Ğ¸Ñ ĞºĞ½Ğ¾Ğ¿ĞºĞ¸ Stop Ğ¸Ğ»Ğ¸ 5 Ğ¼Ğ¸Ğ½ÑƒÑ‚ (9000 ĞºĞ°Ğ´Ñ€Ğ¾Ğ²)
        max_frames = 9000
        
        while cap.isOpened() and frame_count < max_frames and not stop_button:
            ret, frame = cap.read()
            if not ret:
                st.warning("ĞÑˆĞ¸Ğ±ĞºĞ° Ğ¿Ñ€Ğ¸ Ñ‡Ñ‚ĞµĞ½Ğ¸Ğ¸ Ñ Ğ²ĞµĞ±-ĞºĞ°Ğ¼ĞµÑ€Ñ‹")
                break
            
            frame_count += 1
            metrics['total_frames'] = frame_count
            
            annotated_frame = frame.copy()
            current_time = time.time()
            confirmed_violations = set()  # Ğ˜Ğ½Ğ¸Ñ†Ğ¸Ğ°Ğ»Ğ¸Ğ·Ğ¸Ñ€ÑƒĞµĞ¼ Ğ½Ğ° ĞºĞ°Ğ¶Ğ´Ğ¾Ğ¹ Ğ¸Ñ‚ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸
            
            # Ğ”ĞµÑ‚ĞµĞºÑ†Ğ¸Ñ
            if frame_count % frame_skip == 0:
                detections, _ = st.session_state.detector.detect_frame(frame, draw_boxes=False)
                
                # ĞĞ±Ğ½Ğ¾Ğ²Ğ»ĞµĞ½Ğ¸Ğµ Ğ¼ĞµÑ‚Ñ€Ğ¸Ğº
                for class_name in detections:
                    if class_name not in metrics['violations']:
                        metrics['violations'][class_name] = 0
                    metrics['violations'][class_name] += 1
                
                # ĞŸĞ ĞĞ’Ğ˜Ğ›Ğ¬ĞĞĞ¯ Ğ›ĞĞ“Ğ˜ĞšĞ: Ğ¿Ğ¾Ğ»ÑƒÑ‡Ğ°ĞµĞ¼ Ğ¿Ğ¾Ğ´Ñ‚Ğ²ĞµÑ€Ğ¶Ğ´ĞµĞ½Ğ½Ñ‹Ğµ Ğ½Ğ°Ñ€ÑƒÑˆĞµĞ½Ğ¸Ñ
                confirmed_violations, sleep_start_time, detection_time = process_frame_for_detection(
                    current_time, set(detections.keys()), sleep_start_time, sleep_buffer
                )
                
                # â”€â”€â”€ Ğ›ĞĞ“Ğ˜ĞšĞ Ğ—ĞĞŸĞ˜Ğ¡Ğ˜ Ğ’Ğ˜Ğ”Ğ•Ğ â”€â”€â”€
                if confirmed_violations:
                    if not recording:
                        # ĞĞĞ§ĞĞ›Ğ Ğ·Ğ°Ğ¿Ğ¸ÑĞ¸
                        segments_dir, _ = st.session_state.video_processor.setup_output_dirs()
                        filename = st.session_state.video_processor.generate_segment_filename()
                        current_segment_path = os.path.join(segments_dir, filename)
                        
                        st.session_state.video_processor.start_recording(
                            current_segment_path,
                            (width, height),
                            fps
                        )
                        recording = True
                        rec_violations = set(confirmed_violations)
                    else:
                        # ĞĞ±Ğ½Ğ¾Ğ²Ğ»ÑĞµĞ¼ Ñ‚Ğ¸Ğ¿Ñ‹ Ğ½Ğ°Ñ€ÑƒÑˆĞµĞ½Ğ¸Ğ¹ (Ğ¾Ğ±ÑŠĞµĞ´Ğ¸Ğ½ÑĞµĞ¼ Ñ ÑƒĞ¶Ğµ Ğ·Ğ°Ğ¿Ğ¸ÑĞ°Ğ½Ğ½Ñ‹Ğ¼Ğ¸)
                        rec_violations.update(confirmed_violations)
            
            # â”€â”€â”€ Ğ’Ğ˜Ğ—Ğ£ĞĞ›Ğ˜Ğ—ĞĞ¦Ğ˜Ğ¯ ĞĞ ĞšĞĞ”Ğ Ğ• â”€â”€â”€
            # 1. Ğ Ğ¸ÑÑƒĞµĞ¼ GREEN Ğ±Ğ¾ĞºÑÑ‹ Ğ¢ĞĞ›Ğ¬ĞšĞ Ğ´Ğ»Ñ Ğ¿Ğ¾Ğ´Ñ‚Ğ²ĞµÑ€Ğ¶Ğ´ĞµĞ½Ğ½Ñ‹Ñ… Ğ½Ğ°Ñ€ÑƒÑˆĞµĞ½Ğ¸Ğ¹
            if last_detections and last_confirmed_violations:
                # ĞŸĞµÑ€ĞµÑĞµÑ‡ĞµĞ½Ğ¸Ğµ: ĞºĞ°ĞºĞ¸Ğµ Ğ½Ğ°Ñ€ÑƒÑˆĞµĞ½Ğ¸Ñ Ğ¾Ğ´Ğ½Ğ¾Ğ²Ñ€ĞµĞ¼ĞµĞ½Ğ½Ğ¾ Ğ¾Ğ±Ğ½Ğ°Ñ€ÑƒĞ¶ĞµĞ½Ñ‹ Ğ˜ Ğ¿Ğ¾Ğ´Ñ‚Ğ²ĞµÑ€Ğ¶Ğ´ĞµĞ½Ñ‹
                violations_to_draw = last_confirmed_violations & set(last_detections.keys())
                for class_name in violations_to_draw:
                    if class_name in last_detections:
                        boxes_list = last_detections[class_name]
                        for box_info in boxes_list:
                            x1, y1, x2, y2 = map(int, box_info['box'])
                            conf = box_info['conf']
                            # GREEN Ğ´Ğ»Ñ Ğ¿Ğ¾Ğ´Ñ‚Ğ²ĞµÑ€Ğ¶Ğ´ĞµĞ½Ğ½Ñ‹Ñ…
                            cv2.rectangle(annotated_frame, (x1, y1), (x2, y2), (0, 255, 0), 2)
                            label = f"{class_name} {conf:.2f}"
                            cv2.putText(annotated_frame, label, (x1, y1 - 10),
                                       cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)
            
            # 2. Ğ˜Ğ½Ğ´Ğ¸ĞºĞ°Ñ‚Ğ¾Ñ€ Ğ±ÑƒÑ„ĞµÑ€Ğ° ÑĞ½Ğ°
            if 'sleeping' in last_detections:
                if sleep_start_time is not None:
                    time_elapsed = current_time - sleep_start_time
                    if time_elapsed >= sleep_buffer:
                        # Ğ¡Ğ¾Ğ½ Ğ¿Ğ¾Ğ´Ñ‚Ğ²ĞµÑ€Ğ¶Ğ´ĞµĞ½
                        cv2.putText(annotated_frame, "SLEEP CONFIRMED", (50, 50),
                                   cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 255), 2)
                    else:
                        # Ğ–Ğ´ĞµĞ¼ Ğ±ÑƒÑ„ĞµÑ€Ğ°
                        time_left = sleep_buffer - time_elapsed
                        cv2.putText(annotated_frame, f"Sleep Buffer: {time_left:.1f}s", (50, 50),
                                   cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 165, 255), 2)
            
            # 3. ĞšÑ€Ğ°ÑĞ½Ñ‹Ğ¹ Ğ¸Ğ½Ğ´Ğ¸ĞºĞ°Ñ‚Ğ¾Ñ€ Ğ·Ğ°Ğ¿Ğ¸ÑĞ¸ Ğ¢ĞĞ›Ğ¬ĞšĞ Ğ¿Ñ€Ğ¸ Ğ½Ğ°Ñ€ÑƒÑˆĞµĞ½Ğ¸ÑÑ…
            if recording:
                cv2.circle(annotated_frame, (30, 30), 10, (0, 0, 255), -1)
                st.session_state.video_processor.write_frame(annotated_frame)
            
            # â”€â”€â”€ ĞŸĞ ĞĞ’Ğ•Ğ ĞšĞ ĞĞšĞĞĞ§ĞĞĞ˜Ğ¯ Ğ—ĞĞŸĞ˜Ğ¡Ğ˜ â”€â”€â”€
            if recording and last_detection_time:
                if (current_time - last_detection_time) > buffer_seconds:
                    # ĞšĞĞĞ•Ğ¦ Ğ·Ğ°Ğ¿Ğ¸ÑĞ¸
                    st.session_state.video_processor.stop_recording()
                    recording = False
                    
                    # Ğ›Ğ¾Ğ³Ğ¸Ñ€ÑƒĞµĞ¼ Ğ½Ğ°Ñ€ÑƒÑˆĞµĞ½Ğ¸Ğµ
                    st.session_state.violations_log.append({
                        'path': current_segment_path,
                        'time': datetime.now().strftime("%H:%M:%S"),
                        'violation': ", ".join(sorted(rec_violations)),  # Ğ¡Ğ¾Ñ€Ñ‚Ğ¸Ñ€ÑƒĞµĞ¼ Ğ´Ğ»Ñ ĞºĞ¾Ğ½ÑĞ¸ÑÑ‚ĞµĞ½Ñ‚Ğ½Ğ¾ÑÑ‚Ğ¸
                        'student': 'ĞĞ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ°...',
                        'confidence': 'N/A'
                    })
                    last_confirmed_violations = set()  # Ğ¡Ğ±Ñ€Ğ°ÑÑ‹Ğ²Ğ°ĞµĞ¼
            
            # ĞÑ‚Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğµ (ĞºĞ°Ğ¶Ğ´Ñ‹Ğ¹ ĞºĞ°Ğ´Ñ€)
            frame_placeholder.image(annotated_frame, channels="BGR")
            metrics_placeholder.write(f"ĞĞ±Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°Ğ½Ğ¾ ĞºĞ°Ğ´Ñ€Ğ¾Ğ²: {metrics['total_frames']} | "
                                     f"ĞĞ°Ñ€ÑƒÑˆĞµĞ½Ğ¸Ğ¹: {len(st.session_state.violations_log)}")
            
            # ĞŸÑ€Ğ¸Ğ¼ĞµÑ€Ğ½Ñ‹Ğ¹ Ğ¿Ñ€Ğ¾Ğ³Ñ€ĞµÑÑ
            progress = min(frame_count / max_frames, 1.0)
            progress_bar.progress(progress)
        
        cap.release()
        if recording:
            st.session_state.video_processor.stop_recording()
        
        # ĞĞ½Ğ°Ğ»Ğ¸Ğ· Ğ»Ğ¸Ñ† ĞŸĞĞ¡Ğ›Ğ• Ğ·Ğ°Ğ²ĞµÑ€ÑˆĞµĞ½Ğ¸Ñ Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ¸
        if st.session_state.violations_log:
            st.info("ĞĞ½Ğ°Ğ»Ğ¸Ğ· Ğ»Ğ¸Ñ† Ğ² Ğ¾Ğ±Ğ½Ğ°Ñ€ÑƒĞ¶ĞµĞ½Ğ½Ñ‹Ñ… Ğ½Ğ°Ñ€ÑƒÑˆĞµĞ½Ğ¸ÑÑ…...")
            
            if st.session_state.face_recognizer is None and os.path.exists(face_db_path):
                st.session_state.face_recognizer = load_face_recognizer(face_db_path)
            
            if st.session_state.face_recognizer and st.session_state.face_recognizer.is_database_available():
                progress_face = st.progress(0)
                face_status = st.empty()
                
                violations_to_process = [
                    i for i, v in enumerate(st.session_state.violations_log) 
                    if v['student'] == 'ĞĞ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ°...'
                ]
                
                for idx, i in enumerate(violations_to_process):
                    face_status.text(f"ĞĞ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ° Ğ½Ğ°Ñ€ÑƒÑˆĞµĞ½Ğ¸Ñ {idx + 1}/{len(violations_to_process)}...")
                    violation_path = st.session_state.violations_log[i]['path']
                    
                    try:
                        name, score, face_path = st.session_state.face_recognizer.analyze_video_segment(
                            violation_path,
                            face_similarity=face_similarity
                        )
                        st.session_state.violations_log[i]['student'] = name
                        st.session_state.violations_log[i]['confidence'] = f"{score:.0%}"
                    except Exception as e:
                        st.error(f"ĞÑˆĞ¸Ğ±ĞºĞ° Ğ¿Ñ€Ğ¸ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğµ {Path(violation_path).name}: {str(e)}")
                        st.session_state.violations_log[i]['student'] = "ĞĞµ Ğ¾Ğ¿Ğ¾Ğ·Ğ½Ğ°Ğ½"
                        st.session_state.violations_log[i]['confidence'] = "ĞÑˆĞ¸Ğ±ĞºĞ° Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ°"
                    
                    progress_face.progress((idx + 1) / len(violations_to_process))
                
                face_status.empty()
                progress_face.empty()
            else:
                for i, violation in enumerate(st.session_state.violations_log):
                    if violation['student'] == 'ĞĞ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ°...':
                        st.session_state.violations_log[i]['student'] = "ĞĞµ Ğ¾Ğ¿Ğ¾Ğ·Ğ½Ğ°Ğ½"
                        st.session_state.violations_log[i]['confidence'] = "ĞĞµÑ‚ Ğ‘Ğ”"
        
        st.success(f"ĞĞ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ° Ğ·Ğ°Ğ²ĞµÑ€ÑˆĞµĞ½Ğ°! ĞĞ±Ğ½Ğ°Ñ€ÑƒĞ¶ĞµĞ½Ğ¾ {len(st.session_state.violations_log)} Ğ½Ğ°Ñ€ÑƒÑˆĞµĞ½Ğ¸Ğ¹.")
        st.session_state.processing = False
    
    except Exception as e:
        st.error(f"ĞÑˆĞ¸Ğ±ĞºĞ° Ğ¿Ñ€Ğ¸ Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞµ Ğ²ĞµĞ±-ĞºĞ°Ğ¼ĞµÑ€Ñ‹: {e}")
        st.session_state.processing = False

def process_video_file(video_path, video_container, metrics_container, frame_skip=2, buffer_seconds=10, sleep_buffer=10, face_db_path="students.pkl", face_similarity=0.5):
    """ĞĞ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ° Ğ²Ğ¸Ğ´ĞµĞ¾Ñ„Ğ°Ğ¹Ğ»Ğ°"""
    try:
        cap = cv2.VideoCapture(video_path)
        fps = cap.get(cv2.CAP_PROP_FPS)
        width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
        height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
        
        # Ğ¡Ğ¾Ğ·Ğ´Ğ°Ğ½Ğ¸Ğµ Ğ²Ğ¸Ğ´ĞµĞ¾Ğ·Ğ°Ğ¿Ğ¸ÑĞµĞ¹
        st.session_state.video_processor.setup_output_dirs()
        
        # ĞœĞµÑ‚Ñ€Ğ¸ĞºĞ¸
        metrics = {
            'total_frames': 0,
            'violations': {},
            'recording': False,
            'frames_processed': 0
        }
        
        frame_count = 0
        sleep_start_time = None
        last_detection_time = None
        last_recording_end_time = None  # Ğ’Ñ€ĞµĞ¼Ñ ĞºĞ¾Ğ³Ğ´Ğ° Ğ·Ğ°ĞºĞ¾Ğ½Ñ‡Ğ¸Ğ»Ğ°ÑÑŒ Ğ·Ğ°Ğ¿Ğ¸ÑÑŒ
        recording = False
        writer = None
        rec_violations = set()
        current_segment_path = None
        
        # Ğ¡Ğ¾Ñ…Ñ€Ğ°Ğ½ÑĞµĞ¼ Ğ¿Ğ¾ÑĞ»ĞµĞ´Ğ½Ğ¸Ğµ Ğ¾Ğ±Ğ½Ğ°Ñ€ÑƒĞ¶ĞµĞ½Ğ½Ñ‹Ğµ Ğ½Ğ°Ñ€ÑƒÑˆĞµĞ½Ğ¸Ñ Ğ´Ğ»Ñ Ñ€Ğ¸ÑĞ¾Ğ²Ğ°Ğ½Ğ¸Ñ Ğ½Ğ° Ğ²ÑĞµÑ… ĞºĞ°Ğ´Ñ€Ğ°Ñ…
        last_detections = {}
        last_confirmed_violations = set()
        
        progress_bar = st.progress(0)
        status_text = st.empty()
        frame_placeholder = st.empty()
        metrics_placeholder = st.empty()
        
        while cap.isOpened():
            ret, frame = cap.read()
            if not ret:
                break
            
            frame_count += 1
            metrics['total_frames'] = frame_count
            annotated_frame = frame.copy()
            current_time = time.time()
            confirmed_violations = set()  # Ğ˜Ğ½Ğ¸Ñ†Ğ¸Ğ°Ğ»Ğ¸Ğ·Ğ¸Ñ€ÑƒĞµĞ¼ Ğ½Ğ° ĞºĞ°Ğ¶Ğ´Ğ¾Ğ¹ Ğ¸Ñ‚ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸
            
            # â”€â”€â”€ Ğ”Ğ•Ğ¢Ğ•ĞšĞ¦Ğ˜Ğ¯ (ĞºĞ°Ğ¶Ğ´Ñ‹Ğ¹ frame_skip ĞºĞ°Ğ´Ñ€) â”€â”€â”€
            if frame_count % frame_skip == 0:
                detections, _ = st.session_state.detector.detect_frame(frame, draw_boxes=False)
                
                # ĞĞ±Ğ½Ğ¾Ğ²Ğ»ĞµĞ½Ğ¸Ğµ Ğ¼ĞµÑ‚Ñ€Ğ¸Ğº
                for class_name in detections:
                    if class_name not in metrics['violations']:
                        metrics['violations'][class_name] = 0
                    metrics['violations'][class_name] += 1
                
                # ĞŸĞ ĞĞ’Ğ˜Ğ›Ğ¬ĞĞĞ¯ Ğ›ĞĞ“Ğ˜ĞšĞ: Ğ¿Ğ¾Ğ»ÑƒÑ‡Ğ°ĞµĞ¼ Ğ¿Ğ¾Ğ´Ñ‚Ğ²ĞµÑ€Ğ¶Ğ´ĞµĞ½Ğ½Ñ‹Ğµ Ğ½Ğ°Ñ€ÑƒÑˆĞµĞ½Ğ¸Ñ
                confirmed_violations, sleep_start_time, detection_time = process_frame_for_detection(
                    current_time, set(detections.keys()), sleep_start_time, sleep_buffer
                )
                
                # Ğ¡Ğ¾Ñ…Ñ€Ğ°Ğ½ÑĞµĞ¼ Ğ´Ğ»Ñ Ğ²Ğ¸Ğ·ÑƒĞ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¸
                last_detections = detections
                last_confirmed_violations = confirmed_violations
                
                # ĞĞ±Ğ½Ğ¾Ğ²Ğ»ÑĞµĞ¼ Ğ²Ñ€ĞµĞ¼Ñ Ğ¿Ğ¾ÑĞ»ĞµĞ´Ğ½ĞµĞ¹ Ğ´ĞµÑ‚ĞµĞºÑ†Ğ¸Ğ¸ ĞµÑĞ»Ğ¸ ĞµÑÑ‚ÑŒ Ğ¿Ğ¾Ğ´Ñ‚Ğ²ĞµÑ€Ğ¶Ğ´ĞµĞ½Ğ½Ñ‹Ğµ Ğ½Ğ°Ñ€ÑƒÑˆĞµĞ½Ğ¸Ñ
                if confirmed_violations and detection_time:
                    last_detection_time = detection_time
            
            # â”€â”€â”€ Ğ›ĞĞ“Ğ˜ĞšĞ Ğ—ĞĞŸĞ˜Ğ¡Ğ˜ â”€â”€â”€
            if confirmed_violations:
                if not recording:
                    # ĞĞĞ§ĞĞ›Ğ Ğ·Ğ°Ğ¿Ğ¸ÑĞ¸
                    segments_dir, _ = st.session_state.video_processor.setup_output_dirs()
                    filename = st.session_state.video_processor.generate_segment_filename()
                    current_segment_path = os.path.join(segments_dir, filename)
                    
                    st.session_state.video_processor.start_recording(
                        current_segment_path,
                        (width, height),
                        fps
                    )
                    recording = True
                    rec_violations = set(confirmed_violations)
                else:
                    # ĞĞ±Ğ½Ğ¾Ğ²Ğ»ÑĞµĞ¼ Ñ‚Ğ¸Ğ¿Ñ‹ Ğ½Ğ°Ñ€ÑƒÑˆĞµĞ½Ğ¸Ğ¹ (Ğ¾Ğ±ÑŠĞµĞ´Ğ¸Ğ½ÑĞµĞ¼ Ñ ÑƒĞ¶Ğµ Ğ·Ğ°Ğ¿Ğ¸ÑĞ°Ğ½Ğ½Ñ‹Ğ¼Ğ¸)
                    rec_violations.update(confirmed_violations)
            
            # â”€â”€â”€ Ğ’Ğ˜Ğ—Ğ£ĞĞ›Ğ˜Ğ—ĞĞ¦Ğ˜Ğ¯ ĞĞ ĞšĞĞ”Ğ Ğ• â”€â”€â”€
            # 1. Ğ Ğ¸ÑÑƒĞµĞ¼ RED Ğ±Ğ¾ĞºÑÑ‹ Ğ´Ğ»Ñ Ğ’Ğ¡Ğ•Ğ¥ Ğ¾Ğ±Ğ½Ğ°Ñ€ÑƒĞ¶ĞµĞ½Ğ½Ñ‹Ñ… Ğ¾Ğ±ÑŠĞµĞºÑ‚Ğ¾Ğ² Ğ½Ğ° ÑÑ‚Ğ¾Ğ¼ ĞºĞ°Ğ´Ñ€Ğµ
            if last_detections:
                for class_name, boxes_list in last_detections.items():
                    for box_info in boxes_list:
                        x1, y1, x2, y2 = map(int, box_info['box'])
                        conf = box_info['conf']
                        # RED Ğ´Ğ»Ñ Ğ²ÑĞµÑ… Ğ¾Ğ±Ğ½Ğ°Ñ€ÑƒĞ¶ĞµĞ½Ğ½Ñ‹Ñ…
                        cv2.rectangle(annotated_frame, (x1, y1), (x2, y2), (0, 0, 255), 2)
                        label = f"{class_name} {conf:.2f}"
                        cv2.putText(annotated_frame, label, (x1, y1 - 10),
                                   cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 255), 2)
            
            # 2. Ğ˜Ğ½Ğ´Ğ¸ĞºĞ°Ñ‚Ğ¾Ñ€ Ğ±ÑƒÑ„ĞµÑ€Ğ° ÑĞ½Ğ°
            if 'sleeping' in last_detections:
                if sleep_start_time is not None:
                    time_elapsed = current_time - sleep_start_time
                    if time_elapsed >= sleep_buffer:
                        # Ğ¡Ğ¾Ğ½ Ğ¿Ğ¾Ğ´Ñ‚Ğ²ĞµÑ€Ğ¶Ğ´ĞµĞ½
                        cv2.putText(annotated_frame, "SLEEP CONFIRMED", (50, 50),
                                   cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 255), 2)
                    else:
                        # Ğ–Ğ´ĞµĞ¼ Ğ±ÑƒÑ„ĞµÑ€Ğ°
                        time_left = sleep_buffer - time_elapsed
                        cv2.putText(annotated_frame, f"Sleep Buffer: {time_left:.1f}s", (50, 50),
                                   cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 165, 255), 2)
            
            # ĞšÑ€Ğ°ÑĞ½Ñ‹Ğ¹ Ğ¸Ğ½Ğ´Ğ¸ĞºĞ°Ñ‚Ğ¾Ñ€ Ğ·Ğ°Ğ¿Ğ¸ÑĞ¸
            if recording:
                cv2.circle(annotated_frame, (30, 30), 10, (0, 0, 255), -1)
                st.session_state.video_processor.write_frame(annotated_frame)
            
            # â”€â”€â”€ ĞŸĞ ĞĞ’Ğ•Ğ ĞšĞ ĞĞšĞĞĞ§ĞĞĞ˜Ğ¯ Ğ—ĞĞŸĞ˜Ğ¡Ğ˜ â”€â”€â”€
            if recording and last_detection_time:
                if (current_time - last_detection_time) > buffer_seconds:
                    # ĞšĞĞĞ•Ğ¦ Ğ·Ğ°Ğ¿Ğ¸ÑĞ¸
                    st.session_state.video_processor.stop_recording()
                    recording = False
                    
                    # Ğ›Ğ¾Ğ³Ğ¸Ñ€ÑƒĞµĞ¼ Ğ½Ğ°Ñ€ÑƒÑˆĞµĞ½Ğ¸Ğµ
                    st.session_state.violations_log.append({
                        'path': current_segment_path,
                        'time': datetime.now().strftime("%H:%M:%S"),
                        'violation': ", ".join(sorted(rec_violations)),  # Ğ¡Ğ¾Ñ€Ñ‚Ğ¸Ñ€ÑƒĞµĞ¼ Ğ´Ğ»Ñ ĞºĞ¾Ğ½ÑĞ¸ÑÑ‚ĞµĞ½Ñ‚Ğ½Ğ¾ÑÑ‚Ğ¸
                        'student': 'ĞĞ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ°...',
                        'confidence': 'N/A'
                    })
                    last_confirmed_violations = set()  # Ğ¡Ğ±Ñ€Ğ°ÑÑ‹Ğ²Ğ°ĞµĞ¼
            
            # â”€â”€â”€ ĞĞ¢ĞĞ‘Ğ ĞĞ–Ğ•ĞĞ˜Ğ• â”€â”€â”€
            frame_placeholder.image(annotated_frame, channels="BGR")
            metrics_placeholder.write(f"ĞĞ±Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°Ğ½Ğ¾: {metrics['total_frames']} ĞºĞ°Ğ´Ñ€Ğ¾Ğ² | "
                                     f"ĞĞ°Ñ€ÑƒÑˆĞµĞ½Ğ¸Ğ¹: {len(st.session_state.violations_log)}")
            
            progress = min(frame_count / (cap.get(cv2.CAP_PROP_FRAME_COUNT)), 1.0)
            progress_bar.progress(progress)
        
        cap.release()
        if recording:
            st.session_state.video_processor.stop_recording()
        
        # ĞĞ½Ğ°Ğ»Ğ¸Ğ· Ğ»Ğ¸Ñ† ĞŸĞĞ¡Ğ›Ğ• Ğ·Ğ°Ğ²ĞµÑ€ÑˆĞµĞ½Ğ¸Ñ Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ¸ Ğ²ÑĞµĞ³Ğ¾ Ğ²Ğ¸Ğ´ĞµĞ¾
        if st.session_state.violations_log:
            st.info("ĞĞ½Ğ°Ğ»Ğ¸Ğ· Ğ»Ğ¸Ñ† Ğ² Ğ¾Ğ±Ğ½Ğ°Ñ€ÑƒĞ¶ĞµĞ½Ğ½Ñ‹Ñ… Ğ½Ğ°Ñ€ÑƒÑˆĞµĞ½Ğ¸ÑÑ…...")
            
            if st.session_state.face_recognizer is None and os.path.exists(face_db_path):
                st.session_state.face_recognizer = load_face_recognizer(face_db_path)
            
            if st.session_state.face_recognizer and st.session_state.face_recognizer.is_database_available():
                progress_face = st.progress(0)
                face_status = st.empty()
                
                violations_to_process = [
                    i for i, v in enumerate(st.session_state.violations_log) 
                    if v['student'] == 'ĞĞ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ°...'
                ]
                
                for idx, i in enumerate(violations_to_process):
                    face_status.text(f"ĞĞ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ° Ğ½Ğ°Ñ€ÑƒÑˆĞµĞ½Ğ¸Ñ {idx + 1}/{len(violations_to_process)}...")
                    violation_path = st.session_state.violations_log[i]['path']
                    
                    try:
                        name, score, face_path = st.session_state.face_recognizer.analyze_video_segment(
                            violation_path,
                            face_similarity=face_similarity
                        )
                        # ĞĞ±Ğ½Ğ¾Ğ²Ğ»ÑĞµĞ¼ Ğ¢ĞĞ›Ğ¬ĞšĞ ĞµÑĞ»Ğ¸ Ğ¿Ğ¾Ğ»ÑƒÑ‡Ğ¸Ğ»Ğ¸ Ğ²Ğ°Ğ»Ğ¸Ğ´Ğ½Ñ‹Ğ¹ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚
                        st.session_state.violations_log[i]['student'] = name
                        st.session_state.violations_log[i]['confidence'] = f"{score:.0%}"
                    except Exception as e:
                        st.error(f"ĞÑˆĞ¸Ğ±ĞºĞ° Ğ¿Ñ€Ğ¸ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğµ {Path(violation_path).name}: {str(e)}")
                        st.session_state.violations_log[i]['student'] = "ĞĞµ Ğ¾Ğ¿Ğ¾Ğ·Ğ½Ğ°Ğ½"
                        st.session_state.violations_log[i]['confidence'] = "ĞÑˆĞ¸Ğ±ĞºĞ° Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ°"
                    
                    progress_face.progress((idx + 1) / len(violations_to_process))
                
                face_status.empty()
                progress_face.empty()
            else:
                # Ğ•ÑĞ»Ğ¸ Ğ‘Ğ” Ğ»Ğ¸Ñ† Ğ½Ğµ Ğ·Ğ°Ğ³Ñ€ÑƒĞ¶ĞµĞ½Ğ°, Ğ¾Ñ‚Ğ¼ĞµÑ‡Ğ°ĞµĞ¼ Ğ²ÑĞµ ĞºĞ°Ğº "ĞĞµ Ğ¾Ğ¿Ğ¾Ğ·Ğ½Ğ°Ğ½"
                for i, violation in enumerate(st.session_state.violations_log):
                    if violation['student'] == 'ĞĞ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ°...':
                        st.session_state.violations_log[i]['student'] = "ĞĞµ Ğ¾Ğ¿Ğ¾Ğ·Ğ½Ğ°Ğ½"
                        st.session_state.violations_log[i]['confidence'] = "ĞĞµÑ‚ Ğ‘Ğ”"
        
        st.success(f"ĞĞ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ° Ğ·Ğ°Ğ²ĞµÑ€ÑˆĞµĞ½Ğ°! ĞĞ±Ğ½Ğ°Ñ€ÑƒĞ¶ĞµĞ½Ğ¾ {len(st.session_state.violations_log)} Ğ½Ğ°Ñ€ÑƒÑˆĞµĞ½Ğ¸Ğ¹.")
        st.session_state.processing = False  # Ğ¡Ğ±Ñ€Ğ°ÑÑ‹Ğ²Ğ°ĞµĞ¼ Ñ„Ğ»Ğ°Ğ³ Ğ¿Ğ¾ÑĞ»Ğµ Ğ·Ğ°Ğ²ĞµÑ€ÑˆĞµĞ½Ğ¸Ñ
    
    except Exception as e:
        st.error(f"ĞÑˆĞ¸Ğ±ĞºĞ° Ğ¿Ñ€Ğ¸ Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞµ Ğ²Ğ¸Ğ´ĞµĞ¾: {e}")
        st.session_state.processing = False  # Ğ¡Ğ±Ñ€Ğ°ÑÑ‹Ğ²Ğ°ĞµĞ¼ Ñ„Ğ»Ğ°Ğ³ Ğ¿Ñ€Ğ¸ Ğ¾ÑˆĞ¸Ğ±ĞºĞµ Ñ‚Ğ¾Ğ¶Ğµ

def process_video_url(url, video_container, metrics_container, frame_skip=2, buffer_seconds=10, sleep_buffer=10, face_db_path="students.pkl", face_similarity=0.5):
    """ĞĞ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ° Ğ²Ğ¸Ğ´ĞµĞ¾Ğ¿Ğ¾Ñ‚Ğ¾ĞºĞ° Ñ URL"""
    try:
        # ĞŸĞ¾Ğ¿Ñ‹Ñ‚ĞºĞ° Ğ½ĞµÑĞºĞ¾Ğ»ÑŒĞºĞ¾ ÑĞ¿Ğ¾ÑĞ¾Ğ±Ğ¾Ğ² Ğ¾Ñ‚ĞºÑ€Ñ‹Ñ‚ÑŒ Ğ¿Ğ¾Ñ‚Ğ¾Ğº
        st.info(f"ĞŸĞ¾Ğ´ĞºĞ»ÑÑ‡ĞµĞ½Ğ¸Ğµ Ğº Ğ¿Ğ¾Ñ‚Ğ¾ĞºÑƒ: {url}")
        
        cap = cv2.VideoCapture(url)
        
        # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ĞºĞ° Ñ‡Ñ‚Ğ¾ Ğ¿Ğ¾Ñ‚Ğ¾Ğº Ğ¾Ñ‚ĞºÑ€Ñ‹Ñ‚ Ñ Ğ±Ğ¾Ğ»ĞµĞµ Ğ¿Ğ¾Ğ´Ñ€Ğ¾Ğ±Ğ½Ğ¾Ğ¹ Ğ´Ğ¸Ğ°Ğ³Ğ½Ğ¾ÑÑ‚Ğ¸ĞºĞ¾Ğ¹
        if not cap.isOpened():
            st.error("ĞÑˆĞ¸Ğ±ĞºĞ° Ğ¿Ğ¾Ğ´ĞºĞ»ÑÑ‡ĞµĞ½Ğ¸Ñ Ğº Ğ¿Ğ¾Ñ‚Ğ¾ĞºÑƒ!")
            st.info("""
            **Ğ’Ğ¾Ğ·Ğ¼Ğ¾Ğ¶Ğ½Ñ‹Ğµ Ğ¿Ñ€Ğ¸Ñ‡Ğ¸Ğ½Ñ‹:**
            - ĞĞµĞ¿Ñ€Ğ°Ğ²Ğ¸Ğ»ÑŒĞ½Ñ‹Ğ¹ URL (Ğ¿Ñ€Ğ¾Ğ²ĞµÑ€ÑŒÑ‚Ğµ Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ‚)
            - ĞŸĞ¾Ñ‚Ğ¾ĞºĞ¾Ğ²Ñ‹Ğ¹ ÑĞµÑ€Ğ²Ğ¸Ñ Ğ½ĞµĞ´Ğ¾ÑÑ‚ÑƒĞ¿ĞµĞ½ Ğ¸Ğ»Ğ¸ Ñ‚Ñ€ĞµĞ±ÑƒĞµÑ‚ Ğ°ÑƒÑ‚ĞµĞ½Ñ‚Ğ¸Ñ„Ğ¸ĞºĞ°Ñ†Ğ¸Ğ¸
            - Ğ¡ĞµÑ‚ÑŒ Ğ½ĞµĞ´Ğ¾ÑÑ‚ÑƒĞ¿Ğ½Ğ° Ğ¸Ğ»Ğ¸ ÑĞ»Ğ°Ğ±Ğ¾Ğµ ÑĞ¾ĞµĞ´Ğ¸Ğ½ĞµĞ½Ğ¸Ğµ
            
            **ĞŸĞ¾Ğ´Ğ´ĞµÑ€Ğ¶Ğ¸Ğ²Ğ°ĞµĞ¼Ñ‹Ğµ Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ‚Ñ‹ URL:**
            - RTSP Ğ¿Ğ¾Ñ‚Ğ¾ĞºĞ¸: `rtsp://...`
            - HTTP Ğ¿Ğ¾Ñ‚Ğ¾ĞºĞ¸: `http://... Ğ¸Ğ»Ğ¸ https://...`
            - Ğ¤Ğ°Ğ¹Ğ»Ğ¾Ğ²Ñ‹Ğµ Ğ¿Ğ¾Ñ‚Ğ¾ĞºĞ¸: `/path/to/video.mp4`
            - ĞĞ¾Ğ¼ĞµÑ€ ĞºĞ°Ğ¼ĞµÑ€Ñ‹: `0` (Ğ²ĞµĞ±-ĞºĞ°Ğ¼ĞµÑ€Ğ°)
            
            **ĞŸÑ€Ğ¸Ğ¼ĞµÑ€Ñ‹:**
            - `rtsp://admin:password@192.168.1.100:554/stream`
            - `http://example.com/video.m3u8`
            """)
            st.session_state.processing = False
            return
        
        # ĞŸÑ‹Ñ‚Ğ°ĞµĞ¼ÑÑ Ğ¿Ğ¾Ğ»ÑƒÑ‡Ğ¸Ñ‚ÑŒ Ğ¿Ğ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ñ‹, ĞµÑĞ»Ğ¸ Ğ½Ğµ Ğ¿Ğ¾Ğ»ÑƒÑ‡Ğ°ĞµÑ‚ÑÑ - Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµĞ¼ Ğ·Ğ½Ğ°Ñ‡ĞµĞ½Ğ¸Ñ Ğ¿Ğ¾ ÑƒĞ¼Ğ¾Ğ»Ñ‡Ğ°Ğ½Ğ¸Ñ
        fps = cap.get(cv2.CAP_PROP_FPS)
        if fps == 0 or fps is None:
            fps = 30
        
        width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
        height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
        
        if width == 0:
            width = 1280
        if height == 0:
            height = 720
        
        st.success(f"ĞŸĞ¾Ğ´ĞºĞ»ÑÑ‡ĞµĞ½Ğ¾! Ğ Ğ°Ğ·Ñ€ĞµÑˆĞµĞ½Ğ¸Ğµ: {width}x{height}@{fps}fps")
        
        # Ğ¡Ğ¾Ğ·Ğ´Ğ°Ğ½Ğ¸Ğµ Ğ²Ğ¸Ğ´ĞµĞ¾Ğ·Ğ°Ğ¿Ğ¸ÑĞµĞ¹
        st.session_state.video_processor.setup_output_dirs()
        
        # ĞœĞµÑ‚Ñ€Ğ¸ĞºĞ¸
        metrics = {
            'total_frames': 0,
            'violations': {},
            'recording': False,
            'frames_processed': 0
        }
        
        frame_count = 0
        sleep_start_time = None
        last_detection_time = None
        last_recording_end_time = None
        recording = False
        rec_violations = set()
        current_segment_path = None
        last_detections = {}
        last_confirmed_violations = set()
        
        progress_bar = st.progress(0)
        status_text = st.empty()
        frame_placeholder = st.empty()
        metrics_placeholder = st.empty()
        
        st.info("ĞĞ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ° Ğ²Ğ¸Ğ´ĞµĞ¾Ğ¿Ğ¾Ñ‚Ğ¾ĞºĞ° (Ğ½Ğ°Ğ¶Ğ¼Ğ¸Ñ‚Ğµ Stop Ğ´Ğ»Ñ Ğ·Ğ°Ğ²ĞµÑ€ÑˆĞµĞ½Ğ¸Ñ)...")
        
        # Ğ”Ğ»Ñ Ğ¿Ğ¾Ñ‚Ğ¾ĞºĞ¾Ğ² Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ°Ñ‚Ñ‹Ğ²Ğ°ĞµĞ¼ Ğ¾Ğ³Ñ€Ğ°Ğ½Ğ¸Ñ‡ĞµĞ½Ğ½Ğ¾Ğµ ĞºĞ¾Ğ»Ğ¸Ñ‡ĞµÑÑ‚Ğ²Ğ¾ ĞºĞ°Ğ´Ñ€Ğ¾Ğ² Ğ¸Ğ»Ğ¸ Ğ¿Ğ¾ĞºĞ° Ğ½Ğµ Ğ½Ğ°Ğ¶Ğ¼ÑƒÑ‚ Stop
        max_frames = 3000  # ~100 ÑĞµĞºÑƒĞ½Ğ´ Ğ½Ğ° 30 FPS
        
        while cap.isOpened() and frame_count < max_frames:
            ret, frame = cap.read()
            if not ret:
                break
            
            frame_count += 1
            metrics['total_frames'] = frame_count
            
            annotated_frame = frame.copy()
            current_time = time.time()
            confirmed_violations = set()  # Ğ˜Ğ½Ğ¸Ñ†Ğ¸Ğ°Ğ»Ğ¸Ğ·Ğ¸Ñ€ÑƒĞµĞ¼ Ğ½Ğ° ĞºĞ°Ğ¶Ğ´Ğ¾Ğ¹ Ğ¸Ñ‚ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸
            
            # Ğ”ĞµÑ‚ĞµĞºÑ†Ğ¸Ñ ĞºĞ°Ğ¶Ğ´Ñ‹Ğµ frame_skip ĞºĞ°Ğ´Ñ€Ğ¾Ğ²
            if frame_count % frame_skip == 0:
                detections, _ = st.session_state.detector.detect_frame(frame, draw_boxes=False)
                last_detections = detections
                
                # ĞĞ±Ğ½Ğ¾Ğ²Ğ»ĞµĞ½Ğ¸Ğµ Ğ¼ĞµÑ‚Ñ€Ğ¸Ğº
                for class_name in detections:
                    if class_name not in metrics['violations']:
                        metrics['violations'][class_name] = 0
                    metrics['violations'][class_name] += 1
                
                # CONFIRM: ĞŸĞ¾Ğ»ÑƒÑ‡ĞµĞ½Ğ¸Ğµ Ğ¿Ğ¾Ğ´Ñ‚Ğ²ĞµÑ€Ğ¶Ğ´ĞµĞ½Ğ½Ñ‹Ñ… Ğ½Ğ°Ñ€ÑƒÑˆĞµĞ½Ğ¸Ğ¹ Ñ ÑƒÑ‡ĞµÑ‚Ğ¾Ğ¼ Ğ±ÑƒÑ„ĞµÑ€Ğ° ÑĞ½Ğ°
                confirmed_violations, sleep_start_time, detection_time = process_frame_for_detection(
                    current_time, set(detections.keys()), sleep_start_time, sleep_buffer
                )
                last_confirmed_violations = confirmed_violations
                if confirmed_violations and detection_time:
                    last_detection_time = detection_time
                
                # Ğ›Ğ¾Ğ³Ğ¸ĞºĞ° ÑƒĞ¿Ñ€Ğ°Ğ²Ğ»ĞµĞ½Ğ¸Ñ Ğ·Ğ°Ğ¿Ğ¸ÑÑŒÑ
                if confirmed_violations and not recording:
                    # ĞĞĞ§ĞĞ›Ğ Ğ·Ğ°Ğ¿Ğ¸ÑĞ¸
                    segments_dir, _ = st.session_state.video_processor.setup_output_dirs()
                    filename = st.session_state.video_processor.generate_segment_filename()
                    current_segment_path = os.path.join(segments_dir, filename)
                    
                    st.session_state.video_processor.start_recording(
                        current_segment_path,
                        (width, height),
                        fps
                    )
                    recording = True
                    rec_violations = set(confirmed_violations)
                
                # ĞĞ±Ğ½Ğ¾Ğ²Ğ»ÑĞµĞ¼ Ñ‚Ğ¸Ğ¿Ñ‹ Ğ½Ğ°Ñ€ÑƒÑˆĞµĞ½Ğ¸Ğ¹ ĞµÑĞ»Ğ¸ Ğ·Ğ°Ğ¿Ğ¸ÑÑŒ ÑƒĞ¶Ğµ Ğ¸Ğ´ĞµÑ‚
                if confirmed_violations and recording:
                    rec_violations.update(confirmed_violations)
            
            # VISUALIZE: Ğ Ğ¸ÑÑƒĞµĞ¼ Ğ±Ğ¾ĞºÑÑ‹ Ğ´Ğ»Ñ Ğ¿Ğ¾Ğ´Ñ‚Ğ²ĞµÑ€Ğ¶Ğ´ĞµĞ½Ğ½Ñ‹Ñ… Ğ½Ğ°Ñ€ÑƒÑˆĞµĞ½Ğ¸Ğ¹
            if last_detections and last_confirmed_violations:
                violations_to_draw = last_confirmed_violations & set(last_detections.keys())
                if violations_to_draw:
                    annotated_frame = st.session_state.detector.draw_detections(
                        annotated_frame, last_detections, violations_to_draw
                    )
            
            # Ğ”Ğ¾Ğ±Ğ°Ğ²Ğ»ÑĞµĞ¼ Ğ¸Ğ½Ğ´Ğ¸ĞºĞ°Ñ‚Ğ¾Ñ€ Ğ·Ğ°Ğ¿Ğ¸ÑĞ¸ (ĞºÑ€Ğ°ÑĞ½Ñ‹Ğ¹ ĞºÑ€ÑƒĞ³)
            if recording:
                cv2.circle(annotated_frame, (30, 30), 10, (0, 0, 255), -1)
                st.session_state.video_processor.write_frame(annotated_frame)
            
            # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ĞºĞ° Ğ¾ĞºĞ¾Ğ½Ñ‡Ğ°Ğ½Ğ¸Ñ Ğ·Ğ°Ğ¿Ğ¸ÑĞ¸
            if recording and last_detection_time:
                if (current_time - last_detection_time) > buffer_seconds:
                    st.session_state.video_processor.stop_recording()
                    recording = False
                    last_recording_end_time = current_time
                    
                    st.session_state.violations_log.append({
                        'path': current_segment_path,
                        'time': datetime.now().strftime("%H:%M:%S"),
                        'violation': ", ".join(rec_violations),
                        'student': 'ĞĞ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ°...',
                        'confidence': 'N/A'
                    })
            

            
            # ĞÑ‚Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğµ (ĞºĞ°Ğ¶Ğ´Ñ‹Ğ¹ ĞºĞ°Ğ´Ñ€)
            frame_placeholder.image(annotated_frame, channels="BGR")
            metrics_placeholder.write(f"ĞĞ±Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°Ğ½Ğ¾ ĞºĞ°Ğ´Ñ€Ğ¾Ğ²: {metrics['total_frames']} | "
                                     f"ĞĞ°Ñ€ÑƒÑˆĞµĞ½Ğ¸Ğ¹: {len(st.session_state.violations_log)}")
            
            # ĞŸÑ€Ğ¾Ğ³Ñ€ĞµÑÑ (Ğ¿Ñ€Ğ¸Ğ¼ĞµÑ€Ğ½Ñ‹Ğ¹ Ğ´Ğ»Ñ Ğ¿Ğ¾Ñ‚Ğ¾ĞºĞ°)
            progress = min(frame_count / max_frames, 1.0)
            progress_bar.progress(progress)
        
        cap.release()
        if recording:
            st.session_state.video_processor.stop_recording()
        
        # ĞĞ½Ğ°Ğ»Ğ¸Ğ· Ğ»Ğ¸Ñ† ĞŸĞĞ¡Ğ›Ğ• Ğ·Ğ°Ğ²ĞµÑ€ÑˆĞµĞ½Ğ¸Ñ Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ¸ Ğ²ÑĞµĞ³Ğ¾ Ğ²Ğ¸Ğ´ĞµĞ¾
        if st.session_state.violations_log:
            st.info("ĞĞ½Ğ°Ğ»Ğ¸Ğ· Ğ»Ğ¸Ñ† Ğ² Ğ¾Ğ±Ğ½Ğ°Ñ€ÑƒĞ¶ĞµĞ½Ğ½Ñ‹Ñ… Ğ½Ğ°Ñ€ÑƒÑˆĞµĞ½Ğ¸ÑÑ…...")
            
            if st.session_state.face_recognizer is None and os.path.exists(face_db_path):
                st.session_state.face_recognizer = load_face_recognizer(face_db_path)
            
            if st.session_state.face_recognizer and st.session_state.face_recognizer.is_database_available():
                progress_face = st.progress(0)
                face_status = st.empty()
                
                violations_to_process = [
                    i for i, v in enumerate(st.session_state.violations_log) 
                    if v['student'] == 'ĞĞ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ°...'
                ]
                
                for idx, i in enumerate(violations_to_process):
                    face_status.text(f"ĞĞ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ° Ğ½Ğ°Ñ€ÑƒÑˆĞµĞ½Ğ¸Ñ {idx + 1}/{len(violations_to_process)}...")
                    violation_path = st.session_state.violations_log[i]['path']
                    
                    try:
                        name, score, face_path = st.session_state.face_recognizer.analyze_video_segment(
                            violation_path,
                            face_similarity=face_similarity
                        )
                        st.session_state.violations_log[i]['student'] = name
                        st.session_state.violations_log[i]['confidence'] = f"{score:.0%}"
                    except Exception as e:
                        st.error(f"ĞÑˆĞ¸Ğ±ĞºĞ° Ğ¿Ñ€Ğ¸ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğµ {Path(violation_path).name}: {str(e)}")
                        st.session_state.violations_log[i]['student'] = "ĞĞµ Ğ¾Ğ¿Ğ¾Ğ·Ğ½Ğ°Ğ½"
                        st.session_state.violations_log[i]['confidence'] = "ĞÑˆĞ¸Ğ±ĞºĞ° Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ°"
                    
                    progress_face.progress((idx + 1) / len(violations_to_process))
                
                face_status.empty()
                progress_face.empty()
            else:
                for i, violation in enumerate(st.session_state.violations_log):
                    if violation['student'] == 'ĞĞ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ°...':
                        st.session_state.violations_log[i]['student'] = "ĞĞµ Ğ¾Ğ¿Ğ¾Ğ·Ğ½Ğ°Ğ½"
                        st.session_state.violations_log[i]['confidence'] = "ĞĞµÑ‚ Ğ‘Ğ”"
        
        st.success(f"ĞĞ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ° Ğ·Ğ°Ğ²ĞµÑ€ÑˆĞµĞ½Ğ°! ĞĞ±Ğ½Ğ°Ñ€ÑƒĞ¶ĞµĞ½Ğ¾ {len(st.session_state.violations_log)} Ğ½Ğ°Ñ€ÑƒÑˆĞµĞ½Ğ¸Ğ¹.")
        st.session_state.processing = False
    
    except Exception as e:
        st.error(f"ĞÑˆĞ¸Ğ±ĞºĞ° Ğ¿Ñ€Ğ¸ Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞµ Ğ¿Ğ¾Ñ‚Ğ¾ĞºĞ°: {e}")
        st.session_state.processing = False

def process_violations_data(violations_log):
    """ĞĞ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ° Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ½Ğ°Ñ€ÑƒÑˆĞµĞ½Ğ¸Ğ¹ Ğ´Ğ»Ñ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ°"""
    import pandas as pd
    return pd.DataFrame(violations_log) if violations_log else None

def generate_report(violations_log, face_db_path):
    """Ğ“ĞµĞ½ĞµÑ€Ğ¸Ñ€ÑƒĞµÑ‚ Ñ‚ĞµĞºÑÑ‚Ğ¾Ğ²Ñ‹Ğ¹ Ğ¾Ñ‚Ñ‡ĞµÑ‚"""
    try:
        if not st.session_state.face_recognizer and os.path.exists(face_db_path):
            st.session_state.face_recognizer = load_face_recognizer(face_db_path)
        
        return st.session_state.video_processor.generate_report(
            violations_log,
            st.session_state.face_recognizer
        )
    except Exception as e:
        st.error(f"ĞÑˆĞ¸Ğ±ĞºĞ° Ğ¿Ñ€Ğ¸ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸ Ğ¾Ñ‚Ñ‡ĞµÑ‚Ğ°: {e}")
        return None

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ĞĞ¡ĞĞĞ’ĞĞĞ™ Ğ˜ĞĞ¢Ğ•Ğ Ğ¤Ğ•Ğ™Ğ¡
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

st.markdown('<div class="main-title">Ğ¡Ğ¸ÑÑ‚ĞµĞ¼Ğ° ĞœĞ¾Ğ½Ğ¸Ñ‚Ğ¾Ñ€Ğ¸Ğ½Ğ³Ğ° Ğ”Ğ¸ÑÑ†Ğ¸Ğ¿Ğ»Ğ¸Ğ½Ñ‹</div>', 
            unsafe_allow_html=True)

# Ğ‘Ğ¾ĞºĞ¾Ğ²Ğ°Ñ Ğ¿Ğ°Ğ½ĞµĞ»ÑŒ Ñ Ğ½Ğ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ°Ğ¼Ğ¸
st.sidebar.header("")

# ĞĞ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ°Ñ Ğ·Ğ°Ğ³Ñ€ÑƒĞ·ĞºĞ° Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ best.pt
model_path = "best.pt"
if st.session_state.detector is None and os.path.exists(model_path):
    st.session_state.detector = load_detector(model_path)

# ĞŸĞ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ñ‹ Ğ´ĞµÑ‚ĞµĞºÑ†Ğ¸Ğ¸
st.sidebar.subheader("ĞŸĞ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ñ‹ Ğ´ĞµÑ‚ĞµĞºÑ†Ğ¸Ğ¸")
conf_threshold = st.sidebar.slider(
    "ĞŸĞ¾Ñ€Ğ¾Ğ³ ÑƒĞ²ĞµÑ€ĞµĞ½Ğ½Ğ¾ÑÑ‚Ğ¸",
    min_value=0.0,
    max_value=1.0,
    value=0.2,
    step=0.05,
    help="Ğ§ĞµĞ¼ Ğ²Ñ‹ÑˆĞµ - Ñ‚ĞµĞ¼ ÑÑ‚Ñ€Ğ¾Ğ¶Ğµ ĞºÑ€Ğ¸Ñ‚ĞµÑ€Ğ¸Ğ¸"
)

frame_skip = st.sidebar.slider(
    "ĞŸÑ€Ğ¾Ğ¿ÑƒÑĞº ĞºĞ°Ğ´Ñ€Ğ¾Ğ²",
    min_value=1,
    max_value=10,
    value=2,
    help="ĞĞ±Ñ€Ğ°Ğ±Ğ°Ñ‚Ñ‹Ğ²Ğ°Ñ‚ÑŒ ĞºĞ°Ğ¶Ğ´Ñ‹Ğ¹ N-Ğ¹ ĞºĞ°Ğ´Ñ€ (Ğ´Ğ»Ñ ÑĞºĞ¾Ñ€Ğ¾ÑÑ‚Ğ¸)"
)

buffer_seconds = st.sidebar.slider(
    "Ğ‘ÑƒÑ„ĞµÑ€ Ğ·Ğ°Ğ¿Ğ¸ÑĞ¸ (ÑĞµĞº)",
    min_value=5,
    max_value=30,
    value=10,
    help="Ğ¡ĞºĞ¾Ğ»ÑŒĞºĞ¾ ÑĞµĞºÑƒĞ½Ğ´ Ğ¿Ğ¸ÑĞ°Ñ‚ÑŒ Ğ¿Ğ¾ÑĞ»Ğµ Ğ¸ÑÑ‡ĞµĞ·Ğ½Ğ¾Ğ²ĞµĞ½Ğ¸Ñ Ğ½Ğ°Ñ€ÑƒÑˆĞµĞ½Ğ¸Ñ"
)

sleep_buffer = st.sidebar.slider(
    "Ğ‘ÑƒÑ„ĞµÑ€ ÑĞ½Ğ° (ÑĞµĞº)",
    min_value=5,
    max_value=30,
    value=10,
    help="Ğ¢Ğ°Ğ¹Ğ¼ĞµÑ€ Ğ¿Ğ¾Ğ´Ñ‚Ğ²ĞµÑ€Ğ¶Ğ´ĞµĞ½Ğ¸Ñ ÑĞ½Ğ° Ğ¿ĞµÑ€ĞµĞ´ Ğ·Ğ°Ğ¿Ğ¸ÑÑŒÑ"
)

# ĞŸĞ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ñ‹ Ñ€Ğ°ÑĞ¿Ğ¾Ğ·Ğ½Ğ°Ğ²Ğ°Ğ½Ğ¸Ñ Ğ»Ğ¸Ñ†
st.sidebar.subheader("Ğ Ğ°ÑĞ¿Ğ¾Ğ·Ğ½Ğ°Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ»Ğ¸Ñ†")
face_db_path = "students.pkl"
face_similarity = st.sidebar.slider(
    "ĞŸĞ¾Ñ€Ğ¾Ğ³ ÑÑ…Ğ¾Ğ´ÑÑ‚Ğ²Ğ° Ğ»Ğ¸Ñ†Ğ°",
    min_value=0.3,
    max_value=0.9,
    value=0.5,
    step=0.05,
    help="ĞœĞ¸Ğ½Ğ¸Ğ¼Ğ°Ğ»ÑŒĞ½Ğ¾Ğµ ÑÑ…Ğ¾Ğ´ÑÑ‚Ğ²Ğ¾ Ğ´Ğ»Ñ Ğ¾Ğ¿Ğ¾Ğ·Ğ½Ğ°Ğ½Ğ¸Ñ"
)

if st.session_state.detector is None:
    st.warning("ĞœĞ¾Ğ´ĞµĞ»ÑŒ Ğ½Ğµ Ğ·Ğ°Ğ³Ñ€ÑƒĞ¶ĞµĞ½Ğ°. ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑŒÑ‚Ğµ Ğ½Ğ°Ğ»Ğ¸Ñ‡Ğ¸Ğµ Ñ„Ğ°Ğ¹Ğ»Ğ° best.pt")
else:
    # ĞÑĞ½Ğ¾Ğ²Ğ½Ñ‹Ğµ Ğ²ĞºĞ»Ğ°Ğ´ĞºĞ¸
    tab1, tab2 = st.tabs([
        "ĞĞ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ° Ğ²Ğ¸Ğ´ĞµĞ¾",
        "Ğ¡Ñ‚Ğ°Ñ‚Ğ¸ÑÑ‚Ğ¸ĞºĞ°"
    ])
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # Ğ’ĞšĞ›ĞĞ”ĞšĞ 1: ĞĞ‘Ğ ĞĞ‘ĞĞ¢ĞšĞ Ğ’Ğ˜Ğ”Ğ•Ğ
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    with tab1:
        st.header("ĞĞ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ° Ğ²Ğ¸Ğ´ĞµĞ¾")
        
        col_source, col_options = st.columns([2, 1])
        
        with col_source:
            video_source = st.radio(
                "Ğ’Ñ‹Ğ±ĞµÑ€Ğ¸Ñ‚Ğµ Ğ¸ÑÑ‚Ğ¾Ñ‡Ğ½Ğ¸Ğº Ğ²Ğ¸Ğ´ĞµĞ¾:",
                ["Ğ’ĞµĞ±-ĞºĞ°Ğ¼ĞµÑ€Ğ°", "Ğ’Ğ¸Ğ´ĞµĞ¾Ñ„Ğ°Ğ¹Ğ»", "URL Ğ¿Ğ¾Ñ‚Ğ¾ĞºĞ°"],
                horizontal=True
            )
        
        with col_options:
            if st.button("ĞĞ°Ñ‡Ğ°Ñ‚ÑŒ Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºÑƒ", key="process_btn", disabled=st.session_state.processing):
                if not st.session_state.processing:
                    st.session_state.processing = True
        
        # ĞšĞ¾Ğ½Ñ‚ĞµĞ¹Ğ½ĞµÑ€ Ğ´Ğ»Ñ Ğ²Ğ¸Ğ´ĞµĞ¾
        video_container = st.container()
        metrics_container = st.container()
        
        if st.session_state.processing:
            
            if video_source == "Ğ’ĞµĞ±-ĞºĞ°Ğ¼ĞµÑ€Ğ°":
                process_webcam(video_container, metrics_container,
                             frame_skip, buffer_seconds, sleep_buffer,
                             face_db_path, face_similarity)
            
            elif video_source == "Ğ’Ğ¸Ğ´ĞµĞ¾Ñ„Ğ°Ğ¹Ğ»":
                video_file = st.file_uploader(
                    "Ğ—Ğ°Ğ³Ñ€ÑƒĞ·Ğ¸Ñ‚Ğµ Ğ²Ğ¸Ğ´ĞµĞ¾Ñ„Ğ°Ğ¹Ğ»",
                    type=['mp4', 'avi', 'mov', 'mkv']
                )
                if video_file:
                    with tempfile.NamedTemporaryFile(delete=False, suffix='.mp4') as tmp:
                        tmp.write(video_file.read())
                        process_video_file(tmp.name, video_container, metrics_container, 
                                         frame_skip, buffer_seconds, sleep_buffer, 
                                         face_db_path, face_similarity)
            
            elif video_source == "URL Ğ¿Ğ¾Ñ‚Ğ¾ĞºĞ°":
                url = st.text_input("Ğ’Ğ²ĞµĞ´Ğ¸Ñ‚Ğµ URL Ğ²Ğ¸Ğ´ĞµĞ¾Ğ¿Ğ¾Ñ‚Ğ¾ĞºĞ°:")
                if url:
                    process_video_url(url, video_container, metrics_container,
                                     frame_skip, buffer_seconds, sleep_buffer,
                                     face_db_path, face_similarity)
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # Ğ’ĞšĞ›ĞĞ”ĞšĞ 2: Ğ¡Ğ¢ĞĞ¢Ğ˜Ğ¡Ğ¢Ğ˜ĞšĞ Ğ˜ Ğ–Ğ£Ğ ĞĞĞ›
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    with tab2:
        st.header("Ğ¡Ñ‚Ğ°Ñ‚Ğ¸ÑÑ‚Ğ¸ĞºĞ° Ğ½Ğ°Ñ€ÑƒÑˆĞµĞ½Ğ¸Ğ¹")
        
        if st.session_state.violations_log:
            violations_df = process_violations_data(st.session_state.violations_log)
            
            # Ğ¡Ñ‡ĞµÑ‚Ñ‡Ğ¸ĞºĞ¸
            col1, col2, col3, col4 = st.columns(4)
            
            with col1:
                st.metric("Ğ’ÑĞµĞ³Ğ¾ Ğ½Ğ°Ñ€ÑƒÑˆĞµĞ½Ğ¸Ğ¹", len(st.session_state.violations_log))
            
            with col2:
                sleeping_count = sum(
                    1 for v in st.session_state.violations_log 
                    if 'sleeping' in v['violation'].lower()
                )
                st.metric("Ğ¡Ğ¾Ğ½", sleeping_count)
            
            with col3:
                phone_count = sum(
                    1 for v in st.session_state.violations_log 
                    if 'phone' in v['violation'].lower()
                )
                st.metric("Ğ¢ĞµĞ»ĞµÑ„Ğ¾Ğ½", phone_count)
            
            with col4:
                food_count = sum(
                    1 for v in st.session_state.violations_log 
                    if 'food' in v['violation'].lower() or 
                       'bottle' in v['violation'].lower()
                )
                st.metric("Ğ•Ğ´Ğ°/ĞĞ°Ğ¿Ğ¸Ñ‚Ğ¾Ğº", food_count)
            
            # Ğ“Ñ€Ğ°Ñ„Ğ¸ĞºĞ¸
            st.subheader("Ğ Ğ°ÑĞ¿Ñ€ĞµĞ´ĞµĞ»ĞµĞ½Ğ¸Ğµ Ğ¿Ğ¾ Ñ‚Ğ¸Ğ¿Ğ°Ğ¼ Ğ½Ğ°Ñ€ÑƒÑˆĞµĞ½Ğ¸Ğ¹")
            violation_types = {}
            for v in st.session_state.violations_log:
                for vtype in v['violation'].split(', '):
                    violation_types[vtype] = violation_types.get(vtype, 0) + 1
            
            if violation_types:
                import plotly.express as px
                fig = px.bar(
                    x=list(violation_types.keys()),
                    y=list(violation_types.values()),
                    labels={'x': 'Ğ¢Ğ¸Ğ¿ Ğ½Ğ°Ñ€ÑƒÑˆĞµĞ½Ğ¸Ñ', 'y': 'ĞšĞ¾Ğ»Ğ¸Ñ‡ĞµÑÑ‚Ğ²Ğ¾'},
                    color=['#e74c3c', '#e67e22', '#3498db', '#9b59b6'][:len(violation_types)]
                )
                st.plotly_chart(fig, use_container_width=True)
            
            # Ğ’Ñ€ĞµĞ¼ĞµĞ½Ğ½Ğ°Ñ ÑˆĞºĞ°Ğ»Ğ°
            st.subheader("Ğ’Ñ€ĞµĞ¼ĞµĞ½Ğ½Ğ°Ñ ÑˆĞºĞ°Ğ»Ğ° Ğ½Ğ°Ñ€ÑƒÑˆĞµĞ½Ğ¸Ğ¹")
            times = [v['time'] for v in st.session_state.violations_log]
            st.write(f"ĞŸĞµÑ€Ğ²Ğ¾Ğµ Ğ½Ğ°Ñ€ÑƒÑˆĞµĞ½Ğ¸Ğµ: {times[0] if times else 'N/A'}")
            st.write(f"ĞŸĞ¾ÑĞ»ĞµĞ´Ğ½ĞµĞµ Ğ½Ğ°Ñ€ÑƒÑˆĞµĞ½Ğ¸Ğµ: {times[-1] if times else 'N/A'}")
            st.write(f"Ğ’ÑĞµĞ³Ğ¾ Ğ·Ğ°Ğ¿Ğ¸ÑĞ°Ğ½Ğ¾: {len(st.session_state.violations_log)} Ñ„Ñ€Ğ°Ğ³Ğ¼ĞµĞ½Ñ‚Ğ¾Ğ²")
            
            # ĞšĞ½Ğ¾Ğ¿ĞºĞ¸ Ğ´Ğ»Ñ ÑƒĞ¿Ñ€Ğ°Ğ²Ğ»ĞµĞ½Ğ¸Ñ
            st.divider()
            st.subheader("Ğ–ÑƒÑ€Ğ½Ğ°Ğ» Ğ½Ğ°Ñ€ÑƒÑˆĞµĞ½Ğ¸Ğ¹")
            col1, col2 = st.columns([1, 1])
            
            # CSV ÑĞºÑĞ¿Ğ¾Ñ€Ñ‚
            with col1:
                import pandas as pd
                df = pd.DataFrame(st.session_state.violations_log)
                csv = df.to_csv(index=False, encoding='utf-8-sig').encode('utf-8')
                st.download_button(
                    label="Ğ­ĞºÑĞ¿Ğ¾Ñ€Ñ‚ CSV",
                    data=csv,
                    file_name=f"violations_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv",
                    mime="text/csv",
                    key="csv_download_tab2"
                )
            
            with col2:
                if st.button("ĞÑ‡Ğ¸ÑÑ‚Ğ¸Ñ‚ÑŒ", disabled=st.session_state.processing):
                    if not st.session_state.processing:
                        st.session_state.violations_log = []
                        st.success("Ğ–ÑƒÑ€Ğ½Ğ°Ğ» Ğ¾Ñ‡Ğ¸Ñ‰ĞµĞ½")
                        st.rerun()
            
            st.divider()

            st.divider()
            st.subheader("ĞÑ‚Ñ‡ĞµÑ‚")

            if st.button("Ğ¡Ğ³ĞµĞ½ĞµÑ€Ğ¸Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒ Ğ¾Ñ‚Ñ‡ĞµÑ‚", key="gen_report"):
                report_path = generate_report(st.session_state.violations_log, face_db_path)
                if report_path and os.path.exists(report_path):
                    st.success(f"ĞÑ‚Ñ‡ĞµÑ‚ ÑĞ¾Ğ·Ğ´Ğ°Ğ½: {report_path}")

                    with open(report_path, "r", encoding="utf-8") as f:
                        st.text(f.read())

                    with open(report_path, "rb") as f:
                        st.download_button(
                            label="Ğ¡ĞºĞ°Ñ‡Ğ°Ñ‚ÑŒ Ğ¾Ñ‚Ñ‡ĞµÑ‚",
                            data=f.read(),
                            file_name=Path(report_path).name,
                            mime="text/plain",
                            key="download_report"
                        )

            
            for i, violation in enumerate(st.session_state.violations_log, 1):
                with st.expander(
                    f"ĞĞ°Ñ€ÑƒÑˆĞµĞ½Ğ¸Ğµ #{i} | {violation['time']} | {violation['violation']}"
                ):
                    col1, col2 = st.columns([1, 1])
                    
                    with col1:
                        st.write(f"**Ğ’Ñ€ĞµĞ¼Ñ:** {violation['time']}")
                        st.write(f"**ĞĞ°Ñ€ÑƒÑˆĞµĞ½Ğ¸Ğµ:** {violation['violation']}")
                        st.write(f"**Ğ¤Ğ°Ğ¹Ğ»:** {Path(violation['path']).name}")
                    
                    with col2:
                        st.write(f"**Ğ¡Ñ‚ÑƒĞ´ĞµĞ½Ñ‚:** {violation.get('student', 'ĞĞµĞ¸Ğ·Ğ²ĞµÑÑ‚Ğ½Ğ¾')}")
                        st.write(f"**Ğ£Ğ²ĞµÑ€ĞµĞ½Ğ½Ğ¾ÑÑ‚ÑŒ:** {violation.get('confidence', 'N/A')}")
                    
                    if os.path.exists(violation['path']):
                        with open(violation['path'], 'rb') as f:
                            st.download_button(
                                label="Ğ¡ĞºĞ°Ñ‡Ğ°Ñ‚ÑŒ Ğ²Ğ¸Ğ´ĞµĞ¾",
                                data=f.read(),
                                file_name=Path(violation['path']).name,
                                mime="video/mp4",
                                key=f"download_{i}"
                            )
        
        else:
            st.info("ĞĞµÑ‚ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ´Ğ»Ñ Ğ¾Ñ‚Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ñ. ĞĞ±Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°Ğ¹Ñ‚Ğµ Ğ²Ğ¸Ğ´ĞµĞ¾ ÑĞ½Ğ°Ñ‡Ğ°Ğ»Ğ°.")

if __name__ == "__main__":
    pass
